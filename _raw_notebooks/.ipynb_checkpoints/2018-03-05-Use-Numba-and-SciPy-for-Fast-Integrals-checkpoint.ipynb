{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a quick tip to make your integrals super fast in python. Suppose you wanted to integrate a function in 3D. We can start by import nquad from scipy and defining our function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import nquad\n",
    "from math import sqrt, exp, sin, cos\n",
    "\n",
    "def f(x, y, z):\n",
    "    return sin(cos(sqrt(exp(x)**2 + exp(y)**2 + exp(z)**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nquad makes it super easy to integrate a function in any number of dimensions, lets see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.14048187566074577, 1.4506979457578973e-08)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranges=((1, 2), (1, 2), (1, 2))\n",
    "nquad(f, ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how long it took:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.5 ms ± 222 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit nquad(f, ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty good, right? Well let's see if we can do better (because maybe with a different function we'll need to). [Numba](https://numba.pydata.org/) is a just-in-time compiler focused on numeric python. Let's give it a try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works by adding a @jit decorator to our function. It infers the types of the arguments when it sees them and compiles the function into LLVM bytecode. The result can be significantly faster (I've seen easily two orders of magnitude). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def f(x, y, z):\n",
    "    return sin(cos(sqrt(exp(x)**2 + exp(y)**2 + exp(z)**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if it's still correct and how long it takes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.14048187566074577, 1.4506979457578973e-08)\n",
      "10.9 ms ± 17.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "print(nquad(f, ranges))\n",
    "%timeit nquad(f, ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hey! Twice as fast with no work at all! Pretty nice if you ask me. But there is one more layer. The nquad function calls our compiled function from python, meaning that every time it calls the function we're getting python function call overhead. Fortunately, scipy now has support for  *LowLevelCallable* types. The specifics are in the documentation, but basically you can use a c function from scipy and the nquad routine will call it directly, without indirection to the python interpreter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import LowLevelCallable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I never particularly cared for this, until I also saw that Numba now supports generating c functions directly from Python! Scipy needs a c-level function with the signature `double(int, double*)`, so we have to tell numba this is what we want. This is very easy. Unfortunately, this also means we are a bit more restricted in what we can do here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cfunc, types, carray\n",
    "\n",
    "c_sig = types.double(types.intc, types.CPointer(types.double))\n",
    "@cfunc(c_sig)\n",
    "def f(n, data):\n",
    "    total = 0.0\n",
    "    for i in range(n):\n",
    "        total += exp(data[i])**2\n",
    "    return sin(cos(sqrt(total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.14048187566074577, 1.4506979457578973e-08)\n",
      "6.2 ms ± 14.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "new_f = LowLevelCallable(f.ctypes)\n",
    "print(nquad(new_f, ranges))\n",
    "%timeit nquad(new_f, ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! We beat the straightforward numba approach. Unfortunately we had to write a little bit more c-like code. It's not too bad though. I'm betting we can also take advantage of how Numba basically inlines variables it knows at compile time to do basically whatever we want. The cool thing here is that we're calling QUADPACK with a C level callback function, and the performance should be essentially optimal, as the python overhead is minimized. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_standard)",
   "language": "python",
   "name": "conda_standard"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
