<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Abstract Linear Algebra in Python &middot; Evan's Blog
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/colors.css">
  <link rel="stylesheet" href="/public/css/plain.css">
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>


  <body class="Custom-Theme">
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          Evan's Blog
        </a>
      </h1>
      <p class="lead">Overanalyzing Simple Questions since 2016.</p>
    </div>

    <nav class="sidebar-nav">
      <a class="sidebar-nav-item" href="/">Home</a>
      <a class="sidebar-nav-item" href="/Blog">Blog</a>
      <a class="sidebar-nav-item" href="/about">About</a>
      <a class="sidebar-nav-item" href="/CV">CV</a>
      <a class="sidebar-nav-item" href="/LICENSE">License</a>
      <a class="sidebar-nav-icons" href=https://github.com/ecurtin2/ecurtin2.github.io><img src="/images/icons/GitHub_icon.png"></a>
      <a class="sidebar-nav-icons" href=mailto:evanmcurtin@gmail.com><img src="/images/icons/email_icon.png"></a>
      <a class="sidebar-nav-icons" href=https://www.linkedin.com/in/evanmcurtin><img src="/images/icons/LinkedIn_icon.png"></a>
    </nav>

    <p>&copy; 2018. All rights reserved.</p>
  </div>
</div>


    <div class="content container">
      <div class="post">
  <h1 class="post-title">Abstract Linear Algebra in Python</h1>
  <span class="post-date">03 Mar 2018</span>
  <p>Lately I’ve been playing around with the <a href="https://trilinos.org/packages/anasazi/">anasazi</a> library. It’s basically a library that implements algorithms to solve eigenvalue problems that are all completely unaware of the underling data structures. The way this is done is by implementing the algorithms in terms of an <strong>interface</strong>. Basically, this interface is a contract between whoever wrote the library, and whoever is using it. It’s a formal way for the library writer to say “If you give me an object that implements x, and y, this library will do Z with that object.”</p>

<p>This idea is a bit… abstract. <em>And that’s the whole point</em>. Two places where this idea is used constantly are the Python Standard Library and the C++ Standard Template Library (STL). In Python, any object that implements __iter__ and __next__ is automatically considered an iterable, and this opens up a ton of the standard library. In C++, similar functionality is done using iterators, the basic type that all of the STL algorithms work on.</p>

<p>In python, for instance, this allows you to define a custom collection with __iter__ and __next__, and now you automatically get any(), all(), list() and so on, <em>regardless of what it is your collection does</em>.</p>

<p>This has the significant advantage that the algorithms and data structures you use become decoupled. Therefore to implement N algorithms on M data structures, you only need to implement N + M things around a common interface, rather than the N * M combinations of algorithms and data structures. It’s never quite this amazing in practice, but it’s close.</p>

<h2 id="moving-past-numpy-separating-algorithms-and-data-structures-in-linear-algebra">Moving Past numpy: Separating Algorithms and data structures in Linear Algebra</h2>

<p>This is getting long winded. Assume for now that numpy is not doing what we need (say, we need memory - distributed matrices for our problem or something). Rather than rewrite an entire algorithm for another type, why not abstract away numpy in the first place? Then we simply need to write an interface between our algorithm and any data structure we want it to be able to use.</p>

<h2 id="case-study---the-similarity-transform">Case Study - The Similarity Transform</h2>

<p>Python’s duck typing actually makes this almost too easy to be true. However I prefer the explicit abstract method interface: here’s the imports:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code>
<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABC</span><span class="p">,</span> <span class="n">ABCMeta</span><span class="p">,</span> <span class="n">abstractmethod</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">suppress</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span>

</code></pre>
</div>

<p>Lets write out a function for a similarity transform,</p>

<p>$\mathbf{\tilde{A}} = \mathbf{S}^{-1}\mathbf{A}\mathbf{S}$,</p>

<p>but let’s use this idea of an abstract interface. The funny thing is, this looks remarkable like psuedo - code:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code>
<span class="k">def</span> <span class="nf">SimilarityTransform</span><span class="p">(</span><span class="n">STInterface</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>

    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">STInterface</span><span class="p">,</span> <span class="n">SimilarityTransformInterface</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">STInterface</span><span class="o">.</span><span class="n">inverse</span><span class="p">()</span> <span class="err">@</span> <span class="n">other</span> <span class="err">@</span> <span class="n">STInterface</span>

</code></pre>
</div>

<p>Here we assumed that there’s something out there called a SimilarityTransformInterface, and the thing we are being passed is an instance of that. Think for a second: what would this interface need to look like? Well, anything conforming to this interface has to implement an inverse() method as well as the @ operator, the python operator for matrix multliplication (since Python 3.5 - you’re not still using python 2 right?).</p>

<p>The cool thing is, you can express this idea by defining an <em>Abstract Base Class</em> with <em>Abstract Methods</em>. Basically, an abstract base class cannot be instantiated, but it can be subclassed. The rule is, any subclass must implement all methods marked as abstract by the @abstractmethod decorator.</p>

<p>So let’s define our abstract base class:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code>
<span class="k">class</span> <span class="nc">SimilarityTransformInterface</span><span class="p">(</span><span class="n">metaclass</span><span class="o">=</span><span class="n">ABCMeta</span><span class="p">):</span>

    

    <span class="nd">@abstractmethod</span>

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="k">pass</span>

        

    <span class="nd">@abstractmethod</span>

    <span class="k">def</span> <span class="nf">__matmul__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span> <span class="k">pass</span>



    <span class="nd">@classmethod</span>

    <span class="k">def</span> <span class="nf">__subclasshook__</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span> <span class="n">C</span><span class="p">):</span>

        <span class="s">"""Any class that implements all abstract methods of this ABC is a subclass.

        

        This does not require that they inherit from this class!!!        

        """</span>

        <span class="k">if</span> <span class="n">cls</span> <span class="ow">is</span> <span class="n">SimilarityTransformInterface</span><span class="p">:</span>

            <span class="n">requirements_met</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">__class__</span><span class="o">.</span><span class="n">__abstractmethods__</span><span class="p">:</span>

                <span class="n">requirements_met</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">any</span><span class="p">(</span><span class="n">r</span> <span class="ow">in</span> <span class="n">B</span><span class="o">.</span><span class="n">__dict__</span> <span class="k">for</span> <span class="n">B</span> <span class="ow">in</span> <span class="n">C</span><span class="o">.</span><span class="n">__mro__</span><span class="p">))</span>

            <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="n">requirements_met</span><span class="p">):</span>

                <span class="k">return</span> <span class="bp">True</span>

        <span class="k">return</span> <span class="nb">NotImplemented</span>        

</code></pre>
</div>

<p>Here we’ve basically instructed anybody who wants to subclass this class that they must implement inverse() and __matmul__ themselves.</p>

<p>But that’s not all. The __subclasshoook__ method is where it gets real funky. It basically patches python’s issubclass and isinstance methods, and this function as written here basically tells python that  <strong>any class that implements all of the abstractmethods IS A SimilarityTransformInterface</strong>, and there’s no need to inherit from it!</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code>
<span class="k">class</span> <span class="nc">NotOne</span><span class="p">:</span> <span class="k">pass</span>

<span class="k">class</span> <span class="nc">IsOne</span><span class="p">:</span>

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">__matmul__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="k">pass</span>

    

<span class="k">print</span><span class="p">(</span><span class="nb">issubclass</span><span class="p">(</span><span class="n">NotOne</span><span class="p">,</span> <span class="n">SimilarityTransformInterface</span><span class="p">))</span>

<span class="k">print</span><span class="p">(</span><span class="nb">issubclass</span><span class="p">(</span><span class="n">IsOne</span><span class="p">,</span> <span class="n">SimilarityTransformInterface</span><span class="p">))</span>

</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>False

True
</code></pre>
</div>

<p>So now we’ve defined our interface, and we can check to make sure whatever we’re being passed conforms to it. We’re now officially done writing the algorithm. Now all we have to do is write a wrapper for whatever our data types are to make them conform to the interface. I did this for numpy arrays below by copying fromt their documentation:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code>
<span class="k">class</span> <span class="nc">NumpyShim</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>

    <span class="s">"""This wraps a numpy array object into a SimiliarityTransformInterface compliant object."""</span>



    <span class="k">def</span> <span class="nf">__new__</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span> <span class="n">input_array</span><span class="p">):</span>

        <span class="n">obj</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">input_array</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">cls</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">obj</span>

    

    <span class="k">def</span> <span class="nf">__array_finalize__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj</span><span class="p">):</span>

        <span class="k">if</span> <span class="n">obj</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span> <span class="k">return</span>



    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="k">print</span><span class="p">(</span><span class="s">"I just used the np.linalg.inv inverse"</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

</code></pre>
</div>

<p>Ignore the __new__ and __aray_finalize__ functions. They have to do with complications of subclassing numpy arrays. Since numpy already defines the __matmul__ function (for using @ on numpy arrays) all I have to define is the inverse. Numpy also has an inverse function, so I can just call that function within inverse(). Right now this all probably looks like a lot more work to write a one line numpy function, but bear with me.</p>

<p>Let’s first make sure that our similarity transform algorithm works on numpy arrays. We can test this by diagonalizing a symmetric matrix, and seeing if we can use the eigenvectors to transform it into a diagonal matrix of eigenvalues.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code>
<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">A</span> <span class="o">+</span> <span class="n">A</span><span class="o">.</span><span class="n">T</span>

<span class="n">evals</span><span class="p">,</span> <span class="n">evecs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigh</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>



<span class="n">S</span> <span class="o">=</span> <span class="n">NumpyShim</span><span class="p">(</span><span class="n">evecs</span><span class="p">)</span>

<span class="n">M</span> <span class="o">=</span> <span class="n">NumpyShim</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>



<span class="k">print</span><span class="p">(</span><span class="s">"Eigenvalues are: "</span><span class="p">,</span> <span class="n">evals</span><span class="p">)</span>



<span class="n">SimilarityTransform</span><span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>

</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>Eigenvalues are:  [-3.71087275 -1.94249831 -0.09555686  3.90007723]

I just used the np.linalg.inv inverse











NumpyShim([[-3.71087275, -0.        , -0.        ,  0.        ],

           [-0.        , -1.94249831, -0.        ,  0.        ],

           [ 0.        ,  0.        , -0.09555686, -0.        ],

           [ 0.        ,  0.        , -0.        ,  3.90007723]])
</code></pre>
</div>

<p>Wohoo! It works! But that was a lot of work for basically nothing. Here’s where it can get interesting. We know that we have orthogonal eigenvectors of a hermitian matrix, and we know that the inverse of an orthogonal matrix is just it’s transpose. So let’s not waste our time calculating the inverse when we could just do the transpose. But we don’t wanna mess with the algorithm when we know it works:</p>

<p>Let’s do this by making a specialized OrthogonalArray class, whose inverse() method is just the transpose operation. Like so:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code>
<span class="k">class</span> <span class="nc">OrthogonalArray</span><span class="p">(</span><span class="n">NumpyShim</span><span class="p">):</span>

    <span class="s">"""Specializes inverse function for orthogonal numpy arrays"""</span>

    

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>

        <span class="k">assert</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">T</span> <span class="err">@</span> <span class="bp">self</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">))),</span> <span class="mf">0.0</span> <span class="p">)),</span> <span class="s">"Must be orthogonal!"</span>

    

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="k">print</span><span class="p">(</span><span class="s">"I just used the orthogonal array inverse"</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">T</span>

</code></pre>
</div>

<p>Now all we have to do is convert our eigenvectors to be an OrthogonalArray and call the similarity transform on that. Note that it uses the orthogonal array inverse function.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code>
<span class="n">sym</span> <span class="o">=</span> <span class="n">OrthogonalArray</span><span class="p">(</span><span class="n">evecs</span><span class="p">)</span>

<span class="n">SimilarityTransform</span><span class="p">(</span><span class="n">sym</span><span class="p">,</span> <span class="n">A</span><span class="p">)</span>

</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>I just used the orthogonal array inverse











OrthogonalArray([[-3.71087275, -0.        , -0.        ,  0.        ],

                 [-0.        , -1.94249831,  0.        ,  0.        ],

                 [-0.        , -0.        , -0.09555686, -0.        ],

                 [ 0.        ,  0.        , -0.        ,  3.90007723]])
</code></pre>
</div>

<p>Ok that’s pretty neat, isn’t it? We can specialize our data structures to optimize certain restrictions that we know to be true. But the underlying algorithm is unchanged.</p>

<p>If you’re still not convinced, imagine the following: You could use a sparse array, an out-of-memory dask array, or maybe a massively parallel Trilinos or Petsc array to do this <strong>same algorithm</strong> they just <em>need to implement the correct interface</em>.</p>

<h2 id="ok-lets-get-real-weird">Ok let’s get real weird</h2>

<p>Allow me to demonstrate. I’m going to use the same function to do a <em>symbolic</em> similarity transform using sympy.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code>
<span class="kn">from</span> <span class="nn">sympy</span> <span class="kn">import</span> <span class="n">Matrix</span><span class="p">,</span> <span class="n">init_printing</span><span class="p">,</span> <span class="n">symbols</span>

<span class="n">init_printing</span><span class="p">(</span><span class="n">use_unicode</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>



<span class="k">class</span> <span class="nc">SympyShim</span><span class="p">(</span><span class="n">Matrix</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mat</span><span class="p">):</span>

        <span class="bp">self</span> <span class="o">=</span> <span class="n">mat</span>

        

    <span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">inv</span><span class="p">()</span>

</code></pre>
</div>

<p>Again, sympy implements the @ operator for us already. (We could have actually required .inv() instead of .inverse() and used both numpy and sympy, but I wanted to illustrate). So we spend the 10 seconds it takes to implement our interface using sympy Matrices.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code>
<span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">symbols</span><span class="p">(</span><span class="s">'a b'</span><span class="p">)</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">Matrix</span><span class="p">([[</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">],</span> <span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="n">a</span><span class="p">]])</span>

<span class="n">display</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

</code></pre>
</div>

<script type="math/tex; mode=display">% <![CDATA[
\left[\begin{matrix}a & b\\b & a\end{matrix}\right] %]]></script>

<p>Let’s take a look at the eigenvalues and vectors:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code>
<span class="n">pair1</span><span class="p">,</span> <span class="n">pair2</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">eigenvects</span><span class="p">()</span>

<span class="n">display</span><span class="p">(</span><span class="n">pair1</span><span class="p">)</span>

<span class="n">display</span><span class="p">(</span><span class="n">pair2</span><span class="p">)</span>

</code></pre>
</div>

<script type="math/tex; mode=display">\left ( a - b, \quad 1, \quad \left [ \left[\begin{matrix}-1\\1\end{matrix}\right]\right ]\right )</script>

<script type="math/tex; mode=display">\left ( a + b, \quad 1, \quad \left [ \left[\begin{matrix}1\\1\end{matrix}\right]\right ]\right )</script>

<p>Sympy gives us (eigenvalue, multiplicity, eigenvector) tuples as a result, so we have our eigenvectors and values. Lets make a single matrix for the vectors:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code>
<span class="n">sympy_evecs</span> <span class="o">=</span> <span class="n">pair1</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">col_insert</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">pair2</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>

<span class="n">sympy_evecs</span>

</code></pre>
</div>

<script type="math/tex; mode=display">% <![CDATA[
\left[\begin{matrix}-1 & 1\\1 & 1\end{matrix}\right] %]]></script>

<p>Now just convert to our interface type, and use our similarity transform:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code>
<span class="n">s</span> <span class="o">=</span> <span class="n">SympyShim</span><span class="p">(</span><span class="n">sympy_evecs</span><span class="p">)</span>

<span class="n">SimilarityTransform</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>

</code></pre>
</div>

<script type="math/tex; mode=display">% <![CDATA[
\left[\begin{matrix}a - b & 0\\0 & a + b\end{matrix}\right] %]]></script>

<p><strong>What the &gt;^_!</strong> it works!!!  Ok maybe I’m overexaggerating what’s going on here but I’ve demonstrated the core idea here. This is an incredibly simple function that I’m implementing but the core idea is the same. <strong>The duck typing of Python makes it an ideal language to implement abstract algorithms that are independent of the underling datatypes</strong>. Can you do this type of thing in C++? Surely, but get your templates and 1200 character types ready.</p>

<p>I also think that a lot of linear algebra algorithms are a great target for this approach. Writing a lot of the interface code is quite straightforward (it really really really looks like pseudo code) and then you just have to wrap a lot of very commonly implemented tasks anyway (inverse, dot product, etc).</p>

<p>Then you can leverage a lot of linear algebra packages: numpy/scipy, theano, dask, pestc, trilinos, CUDABLAS, tensorflow, etc. with the same algorithms.</p>

<p>You can also do <strong>Matrix free computation where you never even store a matrix</strong>. This problem happens all the time if you’re dealing with very large matrices that are hundreds of thousands or millions of rows.</p>

<p>Maybe we can re implement <a href="https://trilinos.org/packages/anasazi/">anasazi</a> eigensolvers at the algorithm level in python. Then we can have plug-n-play Lanczos, Arnoldi, Davidson, etc algorithms.</p>

<p>Last thing then I’ll be quiet. Imagine using this approach in conjunction with numpy as a proof of concept of your algorithm. Come production time, just write a wrapper for theano and if you do it properly you ought to be able to generate the compute graph of your entire algorithm, and let theano optimize and compile it. I really think this approach to solving problems will really shine when paired with the Python scientific stack.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code>


</code></pre>
</div>


</div>

<div class="related">
  <h2>Related Posts</h2>
  <hr>
  <ul class="related-posts">
    
      <li>
        <h3>
          <a href="/2016/12/14/What-is-a-Molecule/">
            What is a Molecule?
            <small>14 Dec 2016</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/2016/10/26/Scientific_Python_Toolbox/">
            The Scientific Computing Toolkit for Python
            <small>26 Oct 2016</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/2016/09/17/Plot-By-Groups/">
            Plotting by groups using Matplotlib, Seaborn, and Pandas
            <small>17 Sep 2016</small>
          </a>
        </h3>
      </li>
    
  </ul>

  <h2>Comments</h2>
  <hr>

  
<div class="comments">
	<div id="disqus_thread"></div>
	<script type="text/javascript">

	    var disqus_shortname = 'ecurtin2-blog';

	    (function() {
	        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
	        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
	        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	    })();

	</script>
	<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>

</div>

    </div>
    
	<!-- Google Analytics -->
	<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

		ga('create', 'UA-81645801-1', 'auto');
		ga('send', 'pageview', {
		  'page': '//2018/03/03/Abstract-Linear-Algebra-in-Python/',
		  'title': 'Abstract Linear Algebra in Python'
		});
	</script>
	<!-- End Google Analytics -->



  </body>
</html>
